{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import timedelta\n",
    "import pyedflib\n",
    "\n",
    "def process_ecog_data(data_path):\n",
    "    # Load EDF file and prepare data\n",
    "    data = mne.io.read_raw_edf(data_path, preload=True)\n",
    "    df = data.to_data_frame()\n",
    "    X = StandardScaler().fit_transform(df.drop(['time'], axis=1))\n",
    "    scaled_X = pd.DataFrame(data=X, columns=['FrL', 'FrR', 'OcR'])\n",
    "\n",
    "    # Frame segmentation function\n",
    "    def get_frames(df, frame_size, hop_size):\n",
    "        N_FEATURES = 3\n",
    "        frames = []\n",
    "        for i in range(0, len(df) - frame_size, hop_size):\n",
    "            frl = df['FrL'].values[i: i + frame_size]\n",
    "            frr = df['FrR'].values[i: i + frame_size]\n",
    "            ocr = df['OcR'].values[i: i + frame_size]\n",
    "            frames.append([frl, frr, ocr])\n",
    "        return np.asarray(frames).reshape(-1, frame_size, N_FEATURES)\n",
    "\n",
    "    # Segment data into frames\n",
    "    Fs = 400\n",
    "    frame_size = Fs * 10\n",
    "    hop_size = Fs * 3\n",
    "    X = get_frames(scaled_X, frame_size, hop_size)\n",
    "\n",
    "    # Load pre-trained model and make predictions\n",
    "    model = load_model('model.keras')\n",
    "    y_pred_prob = model.predict(X)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # Mapping labels and converting index to time\n",
    "    label_map = {0: 'ds', 1: 'is', 2: 'none', 3: 'swd'}\n",
    "    def index_to_time(index, hop_size, fs=400):\n",
    "        seconds = (index * hop_size) / fs\n",
    "        return str(timedelta(seconds=seconds))\n",
    "\n",
    "    # Compile predictions with timestamps\n",
    "    predictions = []\n",
    "    for idx, pred in enumerate(y_pred):\n",
    "        time_str = index_to_time(idx, hop_size, fs=Fs)\n",
    "        marker = label_map.get(pred, 'unknown')\n",
    "        predictions.append([time_str, marker])\n",
    "\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['time', 'marker'])\n",
    "\n",
    "    # Merge sequences of identical markers\n",
    "    def merge_sequences(df, min_length=3):\n",
    "        result = []\n",
    "        i = 0\n",
    "        while i < len(df):\n",
    "            marker = df.loc[i, 'marker']\n",
    "            if marker == 'none':\n",
    "                i += 1\n",
    "                continue\n",
    "            start_idx = i\n",
    "            while i < len(df) and df.loc[i, 'marker'] == marker:\n",
    "                i += 1\n",
    "            length = i - start_idx\n",
    "            if length >= min_length:\n",
    "                result.append({'time': df.loc[start_idx, 'time'], 'marker': f\"{marker}1\"})\n",
    "                result.append({'time': df.loc[i - 1, 'time'], 'marker': f\"{marker}2\"})\n",
    "        return pd.DataFrame(result)\n",
    "\n",
    "    output_df = merge_sequences(predictions_df)\n",
    "\n",
    "    # Convert the DataFrame timestamps to total seconds (timedelta) for annotation\n",
    "    annotations = []\n",
    "    for _, row in output_df.iterrows():\n",
    "        time = pd.to_timedelta(row['time'])\n",
    "        label = row['marker']\n",
    "        # Set annotation duration to 1 second (you can adjust this value based on your requirements)\n",
    "        annotations.append([time.total_seconds(), time.total_seconds() + 1, label])\n",
    "\n",
    "    # Convert to MNE Annotations format\n",
    "    annotation_times = [a[0] for a in annotations]\n",
    "    annotation_durations = [a[1] - a[0] for a in annotations]\n",
    "    annotation_labels = [a[2] for a in annotations]\n",
    "    annot = mne.Annotations(onset=annotation_times, duration=annotation_durations, description=annotation_labels)\n",
    "\n",
    "    # Apply annotations to the raw data\n",
    "    data.set_annotations(annot)\n",
    "\n",
    "    # Save annotated data back to an EDF file using pyedflib\n",
    "    output_edf_path = data_path.replace('.edf', '_processed_with_annotations.edf')\n",
    "    \n",
    "    # Write data and annotations using pyedflib\n",
    "    with pyedflib.EdfWriter(output_edf_path, len(data.info['ch_names'])) as f:\n",
    "        # Set the sample frequency for each channel\n",
    "        for ch_idx in range(len(data.info['ch_names'])):\n",
    "            f.setSignalHeader(ch_idx, {'sample_rate': 400})  # set the sample rate for each channel\n",
    "\n",
    "        # Write signal data for each channel\n",
    "        for ch_idx in range(len(data.info['ch_names'])):\n",
    "            f.writePhysicalSamples(data.get_data(picks=ch_idx)[0])\n",
    "\n",
    "        # Add annotations (events/markers)\n",
    "        for annotation in annotations:\n",
    "            onset, duration, label = annotation\n",
    "            f.writeAnnotation(onset, duration, label)\n",
    "\n",
    "    # Return DataFrame and EDF file path\n",
    "    return output_df, output_edf_path"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
